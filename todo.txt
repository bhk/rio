TODO

* Unimplemented language features:
  - Manifest variables: true, false, ...
  - Let (other than `=`) & aliasing detection
  - Missing, For, Loop, LoopWhile, While, Act
  - Vectors: `==`, `!=`
  - Records: `==`, `!=`
  - `or` & `and`: lazy/short-circuit
  - `$`
  - `.?`, `<!`
  - assert
  - type constructors
  - `match`
  - `<-`

* Remove negative literals

* Going "full lambda": implementing Rio values as CFun
   - Rio "function" => CFun that expects an ArgBundle argument
   - Other values => CFun that expects property name.
        fenv holds instance & class?  `eval` will bind arg to @0,
        so it must conform to the env interface.  Non-function
        values ("native data") could appear at @1, @2, ...
   - This makes behaviors IFun's, so this is best left until we
     have user-defined behavior and know what it looks like.

* Visualize execution
  - collect execution trace
  - capture start & end of elements

* Record construction alternative approach in IL: first construct type (from
  const data) *then* instantiate?

* riodoc: concepts.txt --> concepts.md
  1. [[a b c]]  -->  [a b c](#a-b-c)
  2. Broken link notifications
  3. "See also: ..."
  4. Index
  5. Comments


---- Long-term

 * "P1" (Phase 1) language definition
 * P1 "bootstrap" interpreter (Lua)
    - parse & walk AST
    - may leak memory (no "free")
    - minimal set of OS bindings
 * P2 interpreter/complier (written in Rio P1, supports P2 superset)
    - compiles to Wasm
    - non-leaking (refcounting)
    - obsoletes bootstrap
 * Choose native VM: Wasmtime, Wasmer, ?
 * OS (WASI?) bindings
 * Web Server
 * P3+: Richer data structuring, lazy/parallel/etc., ...
 * IDE
   - display values (or `pending...`) [computed in parallel VM]

----

Notes:

* Adequate performance (for my expectations) will requires specialization of
  functions *at least* on the types of arguments, in order to eliminate
  dispatching overhead and enable inlining.

  Types cannot generally be predicted at "compile/deploy" time, so run-time
  specialization and compilation may be *required* in those cases.

  Run-time compilation would be triggered by a "guard" failure (type does
  not match the specialized-for type).  But how to perform this check
  efficiently, given duck-typing and structural typing?  [Wherein there is
  no "true identity" of a type that affects behavior; only its interface and
  the behavior thereof distinguishes it from other types.]  Specialization
  can work at a lower level, where "true identity" is in fact known, even if
  it does not factor into behavior.  This might result in run-time
  compilation of a specialized version that results in the same code as a
  previously specialized version for a different type.  Or, short circuiting
  some of the work, it could result in a run-time validation of equivalence.
  In either case, the new specialized type will be recognized on subsequent
  invocations and not require specialization again.  "True identity" could
  be based on where in the program the type or value is constructed --
  `type.id = where` -- or if that type constructing is a function of some
  type value, then `type.id = (where, inputType.id)`.

* The ability to explicitly structure data based on appropriate primitive
  types is important for performance in some cases.  LuaJIT and JS's typed
  arrays provide examples.

  It is unclear to what extent "primitive" types are required outside of
  that context.  For example, adding two UInt16's could produce a Number or
  a UInt16.  Considering only the structuring concerns, we would want
  Number, since that would always succeed and would not present surprising
  semantics (to non-C/ASM programmers).  Considering optimization of inlined
  functions, manipulation of UInt16's in ways that guarantee a UInt16 result
  could facilitate optimization; note that this could be achieved via a
  different "modular addition" meta-method.
