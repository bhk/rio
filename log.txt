# Design Log


## Continuation Lines vs. Nested Blocks

Python and Haskell solutions for this are inelegant.

Haskell 2D syntax is specified as a transformation of the token stream,
generating `{`, `;`, and `}` tokens when not supplied by the programmer.  It
relies on keywords to introduce blocks and lookahead to close blocks.
Roughly:

 1. Generate a "{" token after `let`, `where`, `do`, or `of` (if one is not
    explicitly given) and set the current indentation level to the
    indentation of the next "lexeme".

 2. Generate a ";" when the start of line continues the "current"
    indentation level.

 3. Generate a "}" on dedent, or when it fixes a parsing error. (!)

Python 2D syntax rules are described in terms of pre-processing that joins
lines and emits INDENT and DEDENT tokens before traditional parsing.
Roughly:

 1. Do explicit line joining (trailing `\`)

 2. Do implicit line joining (unmatched `(`, `{`, or `[`)

 3. Convert increasing/decreasing indentation to INDENT and DEDENT tokens.


Python indentation guidelines from PEP-8:

 - Indent multiples of 4 spaces.

 - PEP-8: indent continuations *more* than a following nested block
   (except maybe with `if` statements).

 - Don't use explicit line joining (trailling `\`), when instead you can use
   parens to force implicit joining.  Use explicit line joining when
   necessary (e.g. `with`, `assert`).

 - Break lines *before* a binary operator.


For Rio, we considered distinguishing continuation lines from blocks based
on syntax at the end of the line preceding the block or continuation line.
Possibilities include:

  a) `\` ==> continuation.  [Ugly.]

  b) `:` ==> block.  [Dictionary syntax could produce false-positives.  Ugly
     for function bodies.  Odd-looking when used to include blocks in other
     inline expressions.]

  c) (`=>` | `then:` | ...) ==> block.  [This would forbid continuation
     lines after `=>`, and greatly restrict where blocks could appear.]

  d) (`block:` | `then:` | ...) ==> block.  `block:` would introduce a block
     anywhere within an expression, including function bodies.  [Still a bit
     inelegant to begin functions with `f = (x) => block:`.  Also, consider
     the conflict with structure elements named "block" or "then".]

Instead, we examine the indented line itself.  In Rio, it is easy to
identify "clauses": lines that must be followed vertically by other lines,
such as `if`, `loop`, and assignments.  When an indented line is a clause,
it initiates a block.  Otherwise, we treat it as a continuation line.  (An
"indented line" is one indented further than the current block; it is not
necessarily indented further than a preceding continuation line.)


## Random Notes

 - tab = error; continue as if expanded

 - single-space increase an error;  non-matching dedent an error

 - comment indentation ignored (?)

 - trailing (invisible) whitespace is never significant!

 - `if` appears only in 2D block

 - In mathematics, an equation broken across lines will show an operator at
   the start of continuation lines.  "=" will be attached to the first line.

 - When auto-wrapping: break with lowest precedence operators first.


## Parser Design

A conventional parser type signature for Rio would look something like this:

    parse: String -> (AST | Errors)

Where AST describes an expression, and Error describes a set of errors.  We
get one of the other.

This is inadequate for a live programming environment, where we want to be
able to identify and flag errors without losing all thee information about
the other, valid, parts of the program.  We want to be able to highlight
syntax, allow value exploration, and enhance editing.  For example, changing
the name of a variable in its definition will automatically update the other
references to that variable, and editing within a comment can leverage rich
text formatting features.

SCAM's parser reports errors *in* the parse tree.  It always returns an AST,
which is passed through later phases of compilation that transform the tree,
and may in turn add their own error nodes.  The final result is then
traversed to detect error nodes and display messages before generating an
executable.  This works nicely, but it would become more awkward when we try
to accommodate comments and more error resiliency in the parsing.

Instead, we use:

    parse: String -> (AST, OOB)

OOB contains "out-of-band" data -- anything outside of what naturally fits
in an expression, like comments, extraneous text, invalid characters, and so
on.

Errors may manifest in two ways.  First, an invalid or missing expression
will result in a corresponding error-like AST node as necessary to construct
a well-formed AST strcture.  This will be handled by the evaluator when and
if the expression is encountered.  Second, an OOB entry describes the error
for immediate display in the IDE or terminal output.

Using peg.lua, the AST information is returned via the conventional
"captured values" paradigm, while OOB data is stored in the parser state
that propagates across sequential matches.


## Dynamic Dispatch

The evaluation logic should not switch on type IDs.  The behavior of a value
should be given by its type.

     value = (iface, data)
     iface = { getProperty, ... }
     getProperty: (self, name) -> value


## Preening the Core Language

The core evaluator (`clEval` in interp.lua) is summarized here in a
hypothetical future Rio syntax:

    eval = (expr, env) =>
        ee = newExpr => eval(newExpr, env)

        match expr:
            CVal(value) -> value
            CArg(name) -> env[name]
            CFun(params, body) -> VFun(env, params, body)
            CApp(fn, args) -> match ee(fn):
                VNat(name) -> natives[name](args.map(ee))
                VFun(fenv, params, body) ->
                    assert args.count == params.count
                    eval(body, fenv.bind(params, args.map(ee)))
            CBra(cond, then, else) -> match ee(cond):
                VBool(b) -> b ? ee(then) : ee(else)

As it stands, there is some complexity here that could be moved outside of
the core evaluation loop, into user-defined functions.  While this would at
first appear to negatively affect performance, pushing operations out of the
evaluator and into evaluated code makes them subject to data flow analysis
and CTE.  (For example, argument count validation could be completely
optimized away in most cases.)  This is one strong motivation for having a
minimalist CL.  The other motivation is maintaining simplicity in various
concrete implementations of evaluators (basic evaluation, symbolic
evaluation, etc.).

We can eliminate the `CBra` case and the knowledge of VBool by treating
booleans as functions that accept two function parameters.  The value `true`
calls its first argument, and the value `false` calls its second argument.
Furthermore, in order to make the contract explicit and improve diagnostics,
we place these functions on a *property* of the boolean values.  In Rio:

   true.then_else = (then, else) => then()
   false.then_else = (then, else) => else()

Further, we can remove argument count validation, leaving that for the
invoked function to perform.  In order to support that, we must provide the
argument count to the function, or, better yet, pass it all of its arguments
in a single vector or "arg bundle" object.  This approach is aligned with
some future functionality: variable numbers of arguments, and more complex
argument handling (defaulted and named values, a la Python).

Given the notion of an arg bundle object, we can simplify the CL further and
have it deal only with single-argument functions.  The parameter list goes
away from VFun, environments get simpler, and CArg stores a numeric de
Bruijn index instead of a name.

In order to construct an arg bundle we need to call a constructor -- with a
non-bundled "raw" parameter.  The CL can remain agnostic to *what* the
single parameter contains, but in generating CL during de-sugaring we need
to avoid confusing surface language (Rio) functions with internal functions.
This is easily guaranteed by ensuring internal function values appear only
as the `fn` value in a CApp.  This is currently the case for native
functions like vector and record constructors, which always appear in this
context:

   CApp( CVal(VNat(...)),  ...)

This suggests that eliminating `VNat` values and substituting a new `CNat`
CL record would be more directed to our use case.  At the same time, we can
avoid the bloat (A, below) that follows from the many "curried" function
calls required to construct an argument list with single-argument functions.
Retaining the ability to pass multiple values to a *native* function
(argument count validation is not required there) enables (B).

    (A)  v0 = CVal(argsEmpty)
         v1 = CApp(CApp(CVal(VNat("argsAppend")), v0), ITEM1)
         CApp(CApp(CVal(VNat("argsAppend")), v1), ITEM2)

    (B)  CNat("argsNew", [ITEM1 ITEM2])

That leaves us with:

    eval = (expr, env) => match expr:
        CVal(value) -> value
        CArg(index) -> env[index]
        CFun(body) -> VFun(env, body)
        CApp(fn, arg) -> match eval(fn, env):
            VFun(fenv, body) -> eval(body, fenv.push(eval(arg, env)))
        CNat(name, args) -> natives[name](args.map(a => eval(a, env)))


This comes closer to the ideals of elegance and timelessness that we have in
mind for the CL.

Revisiting booleans in light of these CNat/CFun changes, our Boolean values
have the following CL definitions:

   true.then_else = VFun(emptyEnv, CApp(CNat("argsFirst", [CArg(0)])))
   false.then_else = VFun(emptyEnv, CApp(CNat("argsSecond", [CArg(0)])))

The code to generate the CL for an `if` expression looks like this:

    desugar = (ast, env) => match ast:
        ...
        AST.If(cond, then, else) ->
            te = [then, else].map(a => CFun(desugar(a, env.push([]))))
            CApp(CNat("getProperty", [desugar(cond), "then_else"]),
                 CNat("argsNew", te))
        ...
